{
  "title": "Buforowany Agent Konwersacyjny LLM",
  "config": {
    "step": {
      "user": {
        "title": "Skonfiguruj Buforowanego Agenta LLM",
        "description": "Skonfiguruj backend LLM (Ollama) i plik pamięci podręcznej",
        "data": {
          "ollama_base_url": "Bazowy URL Ollama",
          "model": "Model",
          "system_prompt": "System prompt (opcjonalne)",
          "top_p": "Top-p (nucleus sampling)",
          "top_k": "Top-k",
          "repeat_penalty": "Kara za powtórzenia",
          "min_p": "Min-p",
          "seed": "Seed (-1=losowy)",
          "db_filename": "Nazwa pliku bazy danych (cache)",
          "match_punctuation": "Uwzględniaj interpunkcję (wymaga dokładnej interpunkcji przy dopasowywaniu pytań)",
          "include_datetime": "Dołącz aktualną datę/godzinę do system prompt"
        }
      }
    }
  },
  "options": {
    "step": {
      "init": {
        "title": "Opcje",
        "data": {
          "ollama_base_url": "Bazowy URL Ollama",
          "model": "Model",
          "system_prompt": "System prompt (opcjonalne)",
          "top_p": "Top-p (nucleus sampling)",
          "top_k": "Top-k",
          "repeat_penalty": "Kara za powtórzenia",
          "min_p": "Min-p",
          "seed": "Seed (-1=losowy)",
          "db_filename": "Nazwa pliku bazy danych (cache)",
          "match_punctuation": "Uwzględniaj interpunkcję (wymaga dokładnej interpunkcji przy dopasowywaniu pytań)",
          "include_datetime": "Dołącz aktualną datę/godzinę do system prompt"
        }
      }
    }
  }
}
