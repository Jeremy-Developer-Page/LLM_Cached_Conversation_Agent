{
  "title": "LLM Zwischengespeicherter Konversationsagent",
  "config": {
    "step": {
      "user": {
        "title": "LLM Cached Agent konfigurieren",
        "description": "LLM-Backend (Ollama) und Cache-Datei einrichten",
        "data": {
          "ollama_base_url": "Ollama Basis-URL",
          "model": "Modell",
          "system_prompt": "System-Prompt (optional)",
          "top_p": "Top-p (Nucleus Sampling)",
          "top_k": "Top-k",
          "repeat_penalty": "Wiederholungsstrafe",
          "min_p": "Min-p",
          "seed": "Seed (-1=zufällig)",
          "db_filename": "DB-Dateiname (Cache)",
          "match_punctuation": "Interpunktion beachten (exakte Satzzeichen beim Abgleich der Fragen erforderlich)"
        }
      }
    }
  },
  "options": {
    "step": {
      "init": {
        "title": "Optionen",
        "data": {
          "ollama_base_url": "Ollama Basis-URL",
          "model": "Modell",
          "system_prompt": "System-Prompt (optional)",
          "top_p": "Top-p (Nucleus Sampling)",
          "top_k": "Top-k",
          "repeat_penalty": "Wiederholungsstrafe",
          "min_p": "Min-p",
          "seed": "Seed (-1=zufällig)",
          "db_filename": "DB-Dateiname (Cache)",
          "match_punctuation": "Interpunktion beachten (exakte Satzzeichen beim Abgleich der Fragen erforderlich)"
        }
      }
    }
  }
}
